% !TeX encoding = UTF-8
% !TeX spellcheck = en_GB
% !TeX root = ../thesis.tex

\chapter{Evaluation and Discussion}
\label{chapter:evaluation}

We evaluated whether accurate metadata influences query performance in the PostgresRaw database and assessed the effect of different types of metadata on the query execution time of PostgresRaw. We investigated two scenarios to identify which query types could be optimised more quickly for better execution. We initially provided PostgresSemiRaw with various types of metadata and compared its performance to that of PostgresRaw while executing queries. The second scenario focuses on analysing the query plan for different queries by injecting diverse metadata into PostgresSemiRaw.

Initially, we prepared the various types of metadata for the TPC-H dataset. The provided metadata categories include the table schema, statistics regarding the distribution of the tables and table pages in pg\_class, details about the table's primary keys and foreign keys, and information concerning the NOT NULL and NULL columns. In addition, we selected ten distinct queries based on specific criteria for running the experiment. We used the $\backslash$plan to generate the query execution plan and run the $\backslash$exp command to execute the queries 100 times over PostgresRaw and PostgresSemiRaw databases.

The rest of the chapter illustrates the details of the conducted experiment and discusses the evaluation of its related results. Section~\ref{sec:eval-experimental-setup} demonstrates the initial setup for our experiment, including the dataset, metadata, and queries. Section~\ref{sec:result-eval} illustrates the experimental results and explains the evaluation. Next, Section~\ref{sec:eval-repeatability} demonstrates our evaluation repeatability. Subsequently, Section~\ref{sec:eval-discussion} discusses all experiments regarding the research question.

\section{Operating System}
\label{sec:eval-experimental-setup}

\paragraph{Dataset.}
\label{par:eval-dataset}
To conduct the experiments, we first needed to prepare the data alongside dumping metadata related to our data to evaluate its impact on query execution performance. Initially, we downloaded the TPC-H dataset with the \acrshort{sf} 0.1, which included the files in TBL format. To prepare the dataset and dump the metadata, we used PostgreSQL version 9.6.5, similar to the PostgresRaw version. Before dumping the metadata, we needed to import the TBL data files into the database tables by running the $\backslash$copy command in the PostgreSQL terminal. Due to an extra pipe character as a trailing delimiter in the TPC-H data files, the $\backslash$copy command in PostgreSQL incorrectly identifies the trailing delimiter as an additional column. To resolve this, we ran a data-cleaning script to eliminate any additional trailing delimiters from each row before copying the data into the tables. Afterwards, we exported the data into eight separate \acrshort{csv} files to use as raw data files in PostgresRaw and PostgresSemiRaw.

\paragraph{Metadata.}
\label{par:eval-metadata}
Once we loaded TPC-H data into the database, we executed the ANALYZE command on all tables to update the database statistics in the system catalogs, such as the pg\_statistic. Additionally, by utilising the data from pg\_class, We extracted the table statistics related to the number of rows in the table and the number of disk pages the table occupies. Figure~\ref{fig:query-db-statistics} depicts the query we used to extract the table statistics, and Table~\ref{tab:statistics-eval} indicates the results associated with this query. 

\input{charts/code-query-db-statistics}
\input{tables/tbl-statistics}

In providing PostgresSemiRaw with the collected metadata related to data distribution, we provided the update commands for updating the pg\_class and pg\_statistic. As Figure~\ref{fig:eval-query-statistics-metadata} presents, we manually updated the pg\_class and pg\_statistic. Since manual updates to system catalogs can cause database issues, it is essential to update both catalogs to maintain integrity and consistency throughout the database.

\input{charts-eval-queries/query-statistic-metadata}

In addition to the script for statistics metadata, we provided six individual SQL scripts for creating the TPC-H schema, each offering varying levels of metadata. The first script creates the TPC-H schema with imprecise column data types without considering primary keys, the NOT NULL constraint, and foreign keys. The second script sets up the TPC-H schema, including primary keys but excluding the NOT NULL constraint and foreign key. The third script also creates the TPC-H schema, including primary keys and the NOT NULL constraint, but does not consider foreign keys. The fourth script creates the TPC-H schema, including primary keys, the NOT NULL constraint, and foreign keys, integrating it with the statistics metadata script. The fifth script creates the TPC-H schema, featuring primary keys, the NOT NULL constraint, foreign keys, and the statistics metadata script. Finally, the sixth script creates the TPC-H schema, including primary keys, the NOT NULL constraint, and foreign keys.

\paragraph{Databases.}
\label{par:eval-database}
In terms of running our experiment, we created six different databases. Table~\ref{tab:tbl-eval-db-names-list} illustrates the six unique databases we created for our experiment. Initially, we created a database cluster using the initdb command and specified the data directory. Furthermore, we created the dataset directory under the ownership of the database user account next to the data directory. Afterwards, we uploaded all the \acrshort{csv} files into the dataset directory. Once we set up the database cluster, We utilised all six previously described scripts as init\_schema.sql files to create several PostgresSemiRaw databases alongside a PostgresRaw database for our experiment.

\input{tables/tbl-eval-db-names}

\paragraph{Queries.}
\label{par:eval-queries}
To compare the query execution time on our created databases with various metadata levels, we required a set of relevant queries that could illustrate the impact of different metadata on execution plans. We organised our queries into five categories: simple queries, such as Q1 and Q2; JOIN queries, such as Q3 and Q4; aggregation queries, such as Q5 and Q6; subqueries, such as Q7 and Q8; and complex queries, such as Q9 and Q10 that include sorting and ranking.

Figure~\ref{fig:eval-q1} and Figure~\ref{fig:eval-q2} demonstrate simple SELECT queries which evaluate the PostgresSemiRaw database's ability to optimise filtering and table scans, showing the effect of statistics and column constraints. Additionally, we chose the JOIN queries to evaluate the effect of primary keys, foreign keys, and cardinality estimation in handling the relationship between tables. Figure~\ref{fig:eval-q3} and Figure~\ref{fig:eval-q4} show the JOIN queries we chose for our experiment. To evaluate the statistics and NOT NULL constraints, we chose the aggregate queries to test grouping, sorting, and resource allocation. Figure~\ref{fig:eval-q5} and Figure~\ref{fig:eval-q6} illustrate our selected aggregate queries. Moreover, we chose the subqueries and EXISTS queries to analyse the database's ability to use the statistic metadata to optimise the query plan. Figure~\ref{fig:eval-q7} and Figure~\ref{fig:eval-q8} show our selected subqueries and EXISTS queries. Finally, we selected complex queries that include sorting and ranking of the Figure~\ref{fig:eval-q9} and Figure~\ref{fig:eval-q10} to evaluate how metadata improves query plan optimisation.

\input{charts-eval-queries/q1}
\input{charts-eval-queries/q2}
\input{charts-eval-queries/q3}
\input{charts-eval-queries/q4}
\input{charts-eval-queries/q5}
\input{charts-eval-queries/q6}
\input{charts-eval-queries/q7}
\input{charts-eval-queries/q8}
\input{charts-eval-queries/q9}
\input{charts-eval-queries/q10}

\paragraph{Run Experiment.}
\label{par:eval-run-experiment}
Once we set up the dataset, metadata, and databases, we executed $\backslash$exp~100 on our various databases for each previously described query. This command executed each query a hundred times. Since PostgreSQL, as well as PostgresRaw and PostgresSemiRaw, use caching mechanisms to improve performance, and since we intended to calculate the execution time of each query individually without the influence of previously executed queries catch, we had to clear and restart the database services after running the $\backslash$exp command for each query. Besides $\backslash$exp, we also executed $\backslash$plan on all the queries over all our databases to record the query plan for further analysis. The system used to conduct our experiment has an AMD Ryzen 5 5500U processor (6 cores, 12 threads, with x86\_64 architecture), 3 MiB of L2 cache, and 4 MiB of L3 cache.

\section{Results And Evaluation}
\label{sec:result-eval}

\paragraph{Query Execution Time.}
In this experiment, we measured the latency of query execution times in PostgresSemiRaw by utilising the $\backslash$exp command and collecting the query execution time for each query. We also compared the latency performance of PostgresSemiRaw with different types of metadata and PostgresRaw whilst executing queries to determine which query types could be optimised more quickly for better execution times. Furthermore, we evaluated how different metadata influenced query execution time in PostgresSemiRaw.

While executing queries across different databases, we noted that, contrary to our initial expectations, including table statistics in the metadata of pgSemiRawStatistics and pgSemiRawFK negatively affected query execution times. These unexpected results arise from updating only the pg\_class with the count of tuples and the tables' page size. Figure~\ref{fig:execution_time_group1} illustrates these unexpected results from the pgSemiRawFK and pgSemiRawStatistics databases for queries Q1, Q2, Q3, and Q4, leading us to stop the execution of a $\backslash$exp 100 command, for example, for Q3 after 30 iterations. Additionally, the absence of the results of queries Q4, Q5, Q6, Q7, and Q9 over the pgSemiRawFK and pgSemiRawStatistics databases in the related plots in Figure~\ref{fig:execution_time_group2} arises from the fact that they could not be run. 

\input{charts-eval-exp-time/execution_time_group_1}
\input{charts-eval-exp-time/execution_time_group_2}
Updating all relevant system catalogs related to the count of tuples and the tables' page size to ensure consistency among other connected catalogs. Inconsistent system catalogs can decrease database performance. Because we conducted our experiment with a small dataset, we can run the ANALYZE command to obtain a consistent update of the system catalog. However, the database cannot execute the ANALYZE command on large datasets, highlighting the importance of utilising appropriate data profiling platforms to help extract metadata, such as statistics, from our dataset.

In comparing the execution times of PostgresRaw and PostgresSemiRaw, Figures~\ref{fig:execution_time_group1} and~\ref{fig:execution_time_group2} illustrate that PostgresRaw generally has higher execution times than the PostgresSemiRaw versions, particularly for the first query execution. This indicates that PostgresSemiRaw positively influences ad-hoc queries. Furthermore, pgSemiRawAnalyze consistently demonstrates lower execution times due to ANALYSE providing up-to-date statistics. In particular, pgSemiRawAnalyze excelled in Q5, Q7, and Q9 during the initial execution of these queries, highlighting the impact of statistics metadata on aggregation and grouping queries, as well as on complex queries involving ranking and NOT EXISTS.

Regarding the effect of the primary key, the results demonstrate that the execution time of the pgSemiRawFK for the first query does not improve as we expected, which results from the partial data loading feature of PostgresSemiRaw. In fact, in PostgreSQL, a primary key automatically creates a unique B-tree index on the columns defined as the primary key. If the table is empty, the B-tree index for the primary key will also be empty, as indexes do not store any additional values if there are no rows in the table. Because the tables in PostgresRaw and, similarly, PostgresSemiRaw are initially empty, defining the primary key cannot improve the query execution time on the first run. However, running the query in PostgresRaw and PostgresSemiRaw copies the data from the \acrshort{csv} into the table related to the query, which immediately updates the associated B-tree index. Therefore, when the primary key is included in the metadata, it can enhance the query performance from the second execution onwards on a specific table.

Additionally, pgSemiRawFkPk generally performs better for join queries, such as Q4, as foreign key constraints help the optimiser validate relationships between tables, reducing redundant checks and enabling more efficient join plans. Moreover, pgSemiRawNullValue shows minimal impact on query performance overall since the TPC-H dataset does not have  NOT NULL.


% \input{charts-eval-exp-time-stat/execution_time_group_1}
% \input{charts-eval-exp-time-stat/execution_time_group_2}

\paragraph{Query Plan.}
In this experiment, we evaluated the query plan for different queries over our various PostgresSemiRaw databases compared to PostgresRaw. The effect of different metadata on query plan optimisation varies depending on the optimisation, although we observe the improvement caused by the statistical metadata in all the query groups.

\subparagraph{Simple SELECT Queries (Q1 AND Q2).}
In the pgSemiRawPK database, a lack of statistical information leads the query planner to assume a uniform data distribution, resulting in inefficient \acrshort{seq scan}. Regarding the pgSemiRawNullValue database, knowing that the column O\_TOTALPRICE is NOT NULL should slightly improve the query by eliminating redundant checks. However, we cannot observe the effects of eliminating redundant checks in our experiment, as the TPC-H dataset does not contain NULL values. This observation is also attributed to the small size of the database and the absence of table statistics in its metadata.

Moreover, in the pgSemiRawStatistics database, we expected to provide the statistics to improve cardinality estimates, allowing the query planner to predict the number of rows matching the condition and choose a more efficient access method, such as an index scan. However, it chooses a \acrshort{seq scan} instead. Nevertheless, Figures~\ref{fig:explain-q2-db1} and~\ref{fig:explain-q2-db4} present the decrease in the estimated total cost of the Q2 in the PostgresSemiRaw database in comparison with PostgresRaw, from 2171.00 to 00.00, by providing statistics about the tables. Finally, in the pgSemiRawFK database, foreign keys don't directly affect simple queries, and we do not observe the change in simple SELECT queries, but it does affect JOIN queries.

\input{charts-eval-plan/query_plan_Q2_db1}
\input{charts-eval-plan/query_plan_Q2_db4}

\subparagraph{JOIN Queries (Q3 AND Q4).}
We expect the JOIN queries to be affected by primary and foreign keys and table statistics. Comparing the query planner for Q3 and Q4 in the PostgresRaw with its planner in pgSemiRawPK illustrates that in the pgSemiRawPK database, primary keys lead the planner to choose the index scan. The query also has less estimated total cost. Comparing Figures~\ref{fig:explain-q3-db1} and~\ref{fig:explain-q4-db1} with Figures~\ref{fig:explain-q3-db2} and~\ref{fig:explain-q4-db2} demonstrates the effect of primary keys on the query planner in JOIN queries. However, lacking a foreign key causes the planner optimisation not to know the referee optimisation on the fields. For instance, in the case of Q3, the planner does not know that O\_CUSTKEY always references a valid C\_CUSTKEY, which may result in less efficient join strategies. In the pgSemiRawNullValue, knowledge of NOT NULL constraints does not improve the join by removing unnecessary checks for NULL in the join keys, as the TPC-H dataset does not contain NULL values. Figures~\ref{fig:explain-q3-db3} and~\ref{fig:explain-q4-db3} illustrate how the NULL value constraints affect the JOIN queries.

\input{charts-eval-plan/query_plan_Q3_db1}
\input{charts-eval-plan/query_plan_Q3_db2}
\input{charts-eval-plan/query_plan_Q3_db4}

Moreover, in the pgSemiRawStatistics, understanding the statistics allows the planner optimiser to estimate the size of tables and benefit from the join reordering optimisation strategy. Comparing Figures~\ref{fig:explain-q3-db1} and~\ref{fig:explain-q3-db4} illustrates the decrease in the estimated total cost of Q3 in the pgSemiRawStatistics database compared to PostgresRaw, from 8490.01 to 0.01, by providing statistics about the tables. Additionally, Figures~\ref{fig:explain-q4-db1} and~\ref{fig:explain-q4-db4} also illustrate the decrease in the estimated total cost for Q4, which is also influenced by the data from table statistics. Finally, Figures~\ref{fig:explain-q3-db6} and~\ref{fig:explain-q4-db6} illustrate that having information regarding foreign keys enables the planner optimiser to assume referential integrity, which helps the optimiser to simplify the join execution by using the index scan and index-only scan.

\subparagraph{Aggregation Queries (Q5 AND Q6).}
In general, aggregation queries are significantly affected by metadata such as statistics and column constraints. In our experiment, Figures~\ref{fig:explain-q5-db1} and~\ref{fig:explain-q5-db2} illustrate that the planner optimiser in the pgSemiRawPK database optimiser the index-only scan and index scan instead of \acrshort{seq scan}. Additionally, the primary key positively affects PostgresSemiRaw, reducing the estimated total cost of Q5 and Q6 compared with PostgresRaw. Additionally, comparing Figures~\ref{fig:explain-q5-db3} and~\ref{fig:explain-q6-db3} with Figures~\ref{fig:explain-q5-db1} and~\ref{fig:explain-q5-db2} shows that the NOT NULL constraint does not affect the planner's optimiser, as the TPC-H dataset contains no NULL values.

Regarding the effect of the table statistics on aggregation queries, Figures~\ref{fig:explain-q5-db4} and~\ref{fig:explain-q6-db4} indicate that the query plans for Q5 and Q6 remain unchanged in pgSemiRawStatistics compared to pgSemiRawNullValue and pgSemiRawPK. However, Figure~\ref{fig:execution_time_group2} demonstrates that the table statistics lead to a significant reduction in the execution time of the aggregation queries during the initial execution in pgSemiRawStatistics compared to pgSemiRawNullValue and pgSemiRawPK. Additionally, Figure~\ref{fig:explain-q5-db5} shows that supplying the pgSemiRawFK database with the table's foreign key details does not change our experiment's query plan.

\subparagraph{Subquery And EXISTS Queries (Q7 AND Q8).}
PostgresRaw and, similarly, PostgresSemiRaw cannot handle queries with EXISTS easily. In an EXISTS query, the inner query is often correlated with the outer query. Furthermore, for each row in the outer query, the database must evaluate the inner part to check whether any matching rows exist. PostgresRaw requires access to the raw data file for each row that needs evaluation in EXISTS queries, which impacts the longer query execution time.

Moreover, as the tables in PostgresSemiRaw are initially empty, the primary key's B-tree index remains empty. Therefore, establishing the primary key does not enhance query performance on the initial execution. Consequently, during this first run, the presence of the primary key in pgSemiRawPK is similar to that of a database without foreign keys. This means the database must verify relationships for each outer query, which is computationally expensive.

While the comparison of query plans in Figures~\ref{fig:explain-q8-db1},~\ref{fig:explain-q8-db2},~\ref{fig:explain-q8-db3},~\ref{fig:explain-q8-db4}, and~\ref{fig:explain-q8-db6} demonstrates that the planner optimiser selects the better query optimiser utilising primary keys, NOT NULL utilising foreign keys, and table statistics, PostgresSemiRaw cannot execute queries efficiently with EXISTS all the time. Our experiment shows that if the data related to tables in the EXISTS query is cached in the database due to previously run queries, then PostgresSemiRaw can handle the EXISTS queries.

Additionally, Figures~\ref{fig:explain-q7-db1},~\ref{fig:explain-q7-db2},~\ref{fig:explain-q7-db3},~\ref{fig:explain-q7-db4}, and~\ref{fig:explain-q7-db6} demonstrate that, unlike EXISTS queries, the use of primary keys, NOT NULL constraints, foreign keys, and table statistics can influence the planner's optimiser for NOT EXISTS queries.

\subparagraph{Complex Queries With Sorting And Ranking (Q9 AND Q10).}
The comparison of query plans in Figures~\ref{fig:explain-q9-db1},~\ref{fig:explain-q9-db2},~\ref{fig:explain-q9-db3}, and~\ref{fig:explain-q9-db6} shows that the planner optimiser chooses the most efficient optimisation strategy by providing primary keys, NOT NULL constraints, foreign keys, and table statistics in PostgresSemiRaw. However, PostgresSemiRaw struggles with complex queries like Q10 when a cache of earlier queries is unavailable. It performs more effectively if the data related to tables in complex queries is cached due to previous queries. Otherwise, the enhancements in the query plan strategy, depicted in Figures~\ref{fig:explain-q10-db1},~\ref{fig:explain-q10-db2},~\ref{fig:explain-q10-db3},~\ref{fig:explain-q10-db4}, and~\ref{fig:explain-q10-db6}, fail to improve query performance.

\section{Repeatability}
\label{sec:eval-repeatability}
Due to the importance of the test-retest reliability~\cite{trochim_types_2025}, we needed to check whether, by utilising the same operating system, dataset, and PostgreSQL database version for data dumping, we could obtain the same result. We ran our experiments three times, and there was a correlation coefficient between the results. Additionally, we initially checked the dependencies that can lead to differing results by repeating our experiment with a single person. However, we need to isolate our application's operation so that it is not affected by the other applications on the operating system.

We developed the PostgresSemiRaw reproduction package to enable other scientists to verify and reuse our research results across various operating systems and datasets. We utilised the Docker platform to package the project, which offers a consistent and reproducible environment for the application's operation. Moreover, Docker allows for the distribution of the application as a single unit, simplifying the scaling of development over time by isolating the application from other software and the host system. However, the performance of the application running inside a Docker container is directly affected by resources and the performance of the underlying system on which Docker is running. As a result, the experiment query execution times may differ slightly based on the host machine.

\section{Discussion}
\label{sec:eval-discussion}
The experiments we conducted addressed the research question by including whether PostgresRaw with various options metadata significantly optimises complex operations. The results of all the experiments showed that metadata, such as primary keys, foreign keys, NULL/NOT NULL constraints, and table-level statistics, played a significant part in the runtime and activities with the query plans.

The findings illustrate that statistics metadata is crucial in optimising query
execution, particularly for aggregation, subqueries, and complex queries. Providing the
planner with information regarding the data distribution, cardinality, table size, and statistics metadata assists PostgresSemiRaw in generating a more efficient query plan.

Additionally, the experiments demonstrate that primary keys improve in indexing and lookup operations, particularly for queries with selective filters. However, their impact was less during the initial execution due to PostgresRaw's partial data loading mechanism, which leads to initially empty B-tree indexes.

Furthermore, although the NOT NULL constraint had nearly no effect on query performance, this outcome results from the TPC-H dataset not containing NULL values. However, this constraint may play a more 
 significant role in datasets with high variability in data completeness.

EXISTS and subquery-based queries stressed the drawbacks of PostgresSemiRaw in the absence of metadata or caching mechanisms. These queries were often evaluated for subqueries inside the inner subqueries, which caused computation bottlenecks. Queries with multiple JOIN and aggregations of complex queries also showed that query optimisation depends on the completeness and accuracy of metadata.

The experimental results confirm that integrating metadata into PostgresRaw improves the
performance of different types of queries. Some metadata types, especially the statistical ones, can always enhance the execution times. This finding is an excellent start for future work, such as profiling tools and databases that eliminate data loading, like PostgresSemiRaw.


